import os
import openai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize OpenAI API client
client = openai.OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="none",
)
            
async def generate_chat_stream(prompt):
    """
    Sends a prompt to the OpenAI API and streams the response back.

    Args:
        prompt (str): The user prompt.

    Yields:
        str: Streamed content generated by the AI model.
    """
    completion = client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="",
        stream=True,  # Enable streaming
    )
    for chunk in completion:  # Process each streamed chunk
        content = chunk.choices[0].delta.content
        if content:  # If there is content in the chunk
            yield content
        
def get_model_info():
    """
    Get the model information.
    """
    return {
        "model_name": "GPT-2",
        "model_version": "1.0.0"
    }
